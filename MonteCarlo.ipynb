{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MonteCarlo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWtrWxKMRvH0"
      },
      "source": [
        "\n",
        "# Resolución de Ecuaciones Diferenciales Ordinarias utilizando Integración Monte Carlo\n",
        "\n",
        "### Dehesa Corona Valeria Carolina\n",
        "### Proyecto final para la materia de Análisis Numérico\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ljzlTQWj9y"
      },
      "source": [
        "# Abstract\n",
        "\n",
        "A linear differential equation is a differential equation that is defined by a linear polynomial in the unknown function and its derivatives. An initial value problem or ivp is an ordinary differential equation together with an initial condition which specifies the value of the unknown function at a given point in the domain. The present work aims to establish an implementation to solve these initial value problems using Monte Carlo methods for integration. This will be approached by using an important lemma that allows us to tranform an initial value problem to an equation involving an integral. Finally we´ll conclude that, because of its easy implementation it is a valid option for these type of problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TmU7a98WuM1"
      },
      "source": [
        "#Objetivos\n",
        "Presentar los resultados que permiten el uso de Método Monte Carlo para aproximación de integrales, establecer mediante el Método Monte Carlo un método de solución de problemas de valor inicial y finalmente concluir si vale la pena este acercamiento para resolverlos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGJ03fqTRsUI"
      },
      "source": [
        "# Introducción\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4LaJJrciFmK"
      },
      "source": [
        "El método Monte Carlo aunque computacionalmente \"caro\", resulta relativamente sencillo de implementar y es ampliamente utilizado en el ámbito de la investigación. Por ello, es de mi interés en el presente trabajo establecer un método mediante Integración Monte Carlo para resolver problemas de valor inicial y comprobar su eficacia.\n",
        "\n",
        "Los problemas de valor inicial de ecuaciones diferenciales pueden ser resueltos pasándolos a ecuaciones con integrales. A veces resulta difícil (o hasta imposible) resolver una integral mediante métodos analíticos, por lo que los métodos numéricos llegan a facilitar este paso con un costo de error que varía dependiendo del método.\n",
        "\n",
        "Los métodos Monte Carlo son algoritmos basados en muestreos aleatorios para obtener resutados numéricos. A pesar de que los muestreos aleatorios son sumamente complejos para obtener en la realidad, actualmente mediante computadoras se han construido métodos generadores de números pseudoaleatorios que han facilitado el proceso.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k-VWULJWxQF"
      },
      "source": [
        "#Marco Teórico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1Y9pPOP2awE"
      },
      "source": [
        "## Historia Método Monte Carlo\n",
        "\n",
        "Podríamos decir que los creadores del Método Monte Carlo fueron Stanislaw Ulam y John Von Neumann. A pesar de que la idea fue creada por Ulam, fue Von Neumann quien reconoció el potencial de la implementación. \n",
        "\n",
        "Ulam tenía una fascinación con los procesos estocásticos, tenía como pasatiempo los juegos de azar y disfrutaba de jugar solitario. Conocía bien métodos estadísticos que se basaban en muestreos aleatorios y los consideraba tediosos por la cantidad de operaciones necesarias para su uso. Un día de convalecencia, Ulam tuvo la idea de calcular la probabilidad de ganar un \"Canfield\" (juego de solitario con probabilidades bajas de ganar) y al fallar intentando resolver el problema por combinatoria, se le ocurrió la idea acomodar las cartas cientos de veces y contar cuantas salían exitosas. \n",
        "\n",
        "En la primavera de 1946,  John William Mauchly y John Presper Eckert invitaron a un grupo de renombrados científicos a conocer la computadora ENIAC ( Electronic Numerical Integrator And Computer), entre ellos estaban Ulam y Von Neumann. Entusiasmado con el potencial de la ENIAC, Ulam le platicó a Neumann sus ideas y juntos formularon un posible acercamiento a un problema termonuclear que se trabajó desde el proyecto Manhattan, el proyecto que diseñó y construyó las primeras armas nucleares.\n",
        "\n",
        "En 1947, John Von Neumann envío una carta a Robert Richtmyer,líder de la división teórica del Laboratorio Alamos donde explicaba un posible acercamiento estadístico al problema de la difusión de neutrones en material fisionable.\n",
        "\n",
        "Básicamente, Neumann y Ulam proponían considerar un núcleo esférico de material fisionable rodeado de un \"caparazón\" de material maleable. Asumiendo una distribución inicial de neutrones  en espacio y velocidad pero ignorando los efectos radiativos e hidrodinámicos. La idea era seguir el desarrollo de un largo número de cadenas de neutrones individuales como una consecuencia de\n",
        "dispersión, absorción, y fisión.\n",
        "\n",
        "Después de recibir la respuesta, Neumann y Ulam volvieron a la ENIAC (ahora en su nuevo hogar: Maryland) y comenzaron a programar. Esta investigación fue utilizada para la creación de la Bomba de hidrógeno o Bomba H. Un arma nuclear de segunda generación; más compacta, liviana y más destructiva.\n",
        "\n",
        "En cuanto a su contexto histórico,  resulta irónico pensar en la enorme cantidad de avances científicos que, aunque ahora ayudan a construir un mejor futuro para la humanidad, surgieron motivados por objetivos que el día de hoy consideraríamos inmorales. Sin duda, aquellos que trabajaron en el proyecto Manhattan eran destacables como científicos(algunos son recordados como genios), aunque la historia ha puesto en duda su calidad moral. \n",
        "\n",
        "Una anécdota no tan conocida es que en 1945, Leo Szilard y otros 70 científicos del proyecto Manhattan presentaron la \"Szilárd petition\", una carta dirigida al presidente Truman pidiéndole presentar sus términos a Japón y advirtiendo de su intención de utilizar la bomba en caso de no rendición. La carta nunca llegó al presidente Truman y la bomba llegó a Hiroshima el 6 de agosto de 1945, 9 días antes de la rendición oficial de Japón.\n",
        "\n",
        "\"If you say why not bomb [the Soviets] tomorrow, I say, why not today. If you say today at five o'clock, I say why not one o'clock?\" -John Von Neumann."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6tJ7p6DiNnX"
      },
      "source": [
        "## Problemas de Valor Inicial\n",
        "\n",
        "Tomaremos las EDO de la siguiente forma:\n",
        "\n",
        "$$\\frac{dx}{dt} = f(t,x(t))$$\n",
        "\n",
        "tal que $x(t_0)=x_0$ valor inicial de la ecuación. \n",
        "\n",
        "Esta forma de ecuación diferencial ordinaria es conocida como \"problema de valor inicial\".\n",
        "\n",
        "Un lema interesante que será revisado aquí, es que siempre podemos convertir una ecuación diferencial de primer orden en la siguiente ecuación:\n",
        "\n",
        "$$x(t) = x_0 + \\int_{t_0}^{t} f(s,x(s))ds$$\n",
        "\n",
        "Que convierte el problema en un problema de integración. La implementación de la regla de Simpson para resolver esta  ecuación resulta en las ecuaciones Runge-Kutta de cuarto orden. Los métodos Runge-Kutta, así como el método de Euler son tradicionalmente utilizados para resolver estos problemas de valor inicial.\n",
        "\n",
        "\n",
        "## Soluciones de Ecuaciones Diferenciales Ordinarias de primer orden\n",
        "\n",
        "Para garantizar la existencia de una solución para la ecuación diferencial ordinaria, uno asume que $f$ es continua en el dominio sobre el cual se quiere resolver la ecuación. Para la unicidad de dicha solución $f$ debe cumplir con la condición de Lipschitz, que nos dice:\n",
        "\n",
        "La función $f : X \\rightarrow \\mathbb{R}$ es Lipschitz continua si existe un valor $K$ tal que $|f(x)-f(y)| \\leq K||x-y||$ para toda $x,y \\in X$.\n",
        "\n",
        "Esta condición es más fuerte que la de continuidad. Una función que es diferenciable en todo su dominio es Lipschitz continua si su primera derivada está acotada y toda función continuamente diferenciable es Lipschitz localmente ya que toda función continua es localmente acotada.\n",
        "\n",
        "La razón por la cual es llamada de \"primer orden\" yace en que sólo ya primera derivada de $y$ está en la ecuación.\n",
        "\n",
        "###Lema\n",
        "Tenemos un $I \\subset \\mathbb{R}$ que es un intervalo abierto con $t_o \\in I$, donde $D \\subset \\mathbb{R} \\times \\mathbb{R}^n $ conjunto abierto, $f: D \\rightarrow \\mathbb{R}^n $ función continua que satisface $(t,x(t)) \\in D, \\forall t \\in I$. Entonces existe una solución al problema de valor inicial si y sólo si:\n",
        "\n",
        "$$x(t) = x_0 + \\int_{t_0}^{t} f(s,x(s))ds$$\n",
        "\n",
        "$\\underline{Dem}$. Si $x(t)$ solución al problema de valor inicial, entonces es una antiderivada de $f(t,x(t))$ en $I$ y por Teorema fundamental del Cálculo:\n",
        "\n",
        "$$x(t) - x(t_0) = \\int_{t_0}^{t} f(s,x(s))ds$$\n",
        "\n",
        "Como $x(t_0)=x_0$ obtenemos la ecuación del lema.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cnelk8qrex3"
      },
      "source": [
        "## Integración Monte Carlo\n",
        "Antes de revisar la técnica mediante la cual se integra utilizando el método Monte Carlo, revisaremos los conceptos y resultados que hacen posible su uso.\n",
        "###Conceptos útiles\n",
        "**Variable aleatoria**\n",
        "Una variable aleatoria es la cantidad resultante de una función asociada a algún experimento que involucra azar. Por ejemplo, tirando dos dados podríamos tomar como v. a el número que salga y  $E_m = \\{ 1 , 2, 3, 4, 5, 6\\}$ es su espacio muestral.\n",
        "\n",
        "**Distribución de probabilidad** La distribución de probabilidad de una variable aleatoria es una función que asigna a cada suceso definido sobre la variable la probabilidad de que dicho suceso ocurra.\n",
        "\n",
        "**Esperanza** La esperana es el valor medio o esperado de una distribución. $\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} xf(x)dx$ en el caso continuo y $\\mathbb{E}[X]= \\sum_{i}^{i}x_if\\left(X_{i}\\right)$ en el caso discreto.\n",
        "\n",
        "**Varianza** La varianza de $X$ es la medida de dispersión de la distribución. $var(X) = \\mathbb{E}[X^2]- (\\mathbb{E}[X])^2$\n",
        "\n",
        "**Distribución Uniforme**\n",
        "Para este proyecto solo necesitamos saber que la distribución uniforme continua es una familia de distribuciones de probabilidad para variables aleatorias continuas, tales que para cada miembro de la familia, todos los intervalos de igual longitud en la distribución en su rango son igualmente probables. La escribiremos como $\\sim \\mathbb{U}_(a,b)$ donde $a, b$ extremos del intervalo.\n",
        "\n",
        "**Distribución Normal**\n",
        "La distribución Normal es  una de las distribuciones de probabilidad de variable continua que con más frecuencia aparece en estadística y en la teoría de probabilidades. La gráfica de su función de densidad tiene una forma acampanada y es simétrica respecto de un determinado parámetro estadístico. Esta curva se conoce como campana de Gauss y es el gráfico de una función gaussiana.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21vkUUoeIcPK"
      },
      "source": [
        "###Teoremas importantes\n",
        "\n",
        "Para poder continuar con el desarrollo del proyecto y cumplir el objetivo, primero revisaremos los teoremas que hacen esto posible. Los teoremas ahondan en los conceptos de probabilidad revisados anteriormente.\n",
        "####**Ley de los grandes números**\n",
        "El promedio de $M$ variables aleatorias independientes e idénticamente distribuidas $x_i$, $\\bar{X}_M = \\frac{1}{M}\\sum_{i=1}^{M} x_i$, converge a $\\mathbb{E}[X]$ cuando M es suficientemente grande. Es decir,\n",
        "\n",
        "$$\\mathbb{P} (\\lim_{M\\to\\infty} \\bar{X}_M = \\mathbb{E}[X]) = 1$$\n",
        "La probabilidad de que el límite de $\\bar{X}_M$ con M muy grande sea igual a la esperanza de de $X$ es 1. Esto porque tenemos la posibilidad de que el muestreo  sea tal que el promedio no sea igual a la esperanza, pero conforme M se hace grande. la probabilidad de que esto ocurra tiende a 0.\n",
        "\n",
        "####**Teorema fundamental de Monte Carlo**\n",
        "Consideremos la variable aleatoria $G_{N}$, promedio de una función $g\\left(X_{i}\\right)$ con $x_i$ independientes e idénticamente distribuidas, es decir \n",
        "\n",
        "$$G_{N}=\\frac{1}{N}\\sum_{i=1}^{N}g\\left(X_{i}\\right) \\tag{1}$$\n",
        "\n",
        "Cuya esperanza y varianza son respectivamente\n",
        "\n",
        "$$\\mathbb{E}[G_N]=\\mathbb{E}[g(X)],var(G_N)=\\frac{var(g(X))}{N}\\tag{2}$$\n",
        "\n",
        "Al promedio $G_N$ se le llama estimador de $\\mathbb{E}[g(X)]$, pues su esperanza vale:\n",
        "\n",
        "$$\\mathbb{E}[G_N]=\\mathbb{E}[g(X)]=\\int_{-\\infty}^{\\infty}g(x)f(x)dx\\tag{3}$$\n",
        "\n",
        "Donde $X_i\\sim f$. Es decir que podemos evaluar la integral anterior generando un conjunto de $N$ variables aleatorias $X_{i}$ según $f(x)$ y evaluando $g(x)$ para cada una de ellas. \n",
        "\n",
        "El estimador (1) (la media aritmética de los $g(x)$ generados) nos da el valor de la integral (3). \n",
        "\n",
        "Ademas podemos ver que la varianza del estimador disminuye al crecer $N$. De hecho, aplicando la desigualdad de Chebyshev a la variable aleatoria $G_N$ con $\\sigma^{2}=var(G_N),\\,x^{2}=\\frac{\\sigma^{2}}{\\delta}\\,y\\,\\delta>0$,\n",
        "\n",
        "$$P(|G_N-\\mathbb{E}[G_N]|\\geq[\\frac{var(G_N)}{\\delta}]^{\\frac{1}{2}})\\leq\\delta \\tag{4}$$\n",
        "\n",
        "Lo que significa que generando una muestra suficientemente grande $(N >> \\frac{1}{\\delta})$ la probabilidad de que el estimador se aleje del valor esperado $g(X)$ es tan pequeña como se desee.\n",
        "\n",
        "####**Teorema del límite Central**\n",
        "Si la variable aleatoria $G_N$ toma valores $g_N$ y definimos:\n",
        "\n",
        "$$t_N = \\frac{g_N-\\mathbb{E}[g(X)]}{\\sqrt{var(G_N)}} = \\frac{g_N- \\mathbb{E}[g(X)]}{\\sqrt{var(g(X))}/\\sqrt{N}}$$\n",
        "\n",
        "El teorema del límite central establece que:\n",
        "\n",
        "$$\\lim_{N\\to\\infty}\\mathbb{P}(a<t_N<b)=\\int_{a}^{b} \\frac{e^{-\\frac{t^2}{2}}}{\\sqrt{2\\pi}}dt\\tag{1}$$\n",
        "\n",
        "Que nos dice que cuando N es lo suficientemente grande, los valores de $G_N$ tienen una distribución Normal de media $\\mu = \\mathbb{E}[g(X)]$ y varianza $\\sigma ^2 = var(g(X))$. \n",
        "\n",
        "Una vez considerados los anteriores teoremas, notamos que se concentran en la noción de que el muestreo aleatorio que tomaremos para la integración Monte Carlo se puede aproximar tanto como queramos pero tendremos que hacer muestreos lo suficientemente grandes y también considerar un gran número de iteraciones. Esto podría conllevar un alto costo computacional.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoRAybyvddve"
      },
      "source": [
        "\n",
        "Ahora revisaremos la técnica que utilizaremos para implementar el método Monte Carlo en la resolución de la integral que representa el IVP(Initial Value Problem) de la EDO de  primer orden.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a05dwKTiIfF3"
      },
      "source": [
        "\n",
        "###Técnica de integración Monte Carlo\n",
        "\n",
        "## Métodos Monte Carlo\n",
        "\n",
        "La integral de la función es igual al área debajo de la curva. La longitud del intervalo $b-a$ por el valor promedio de la función, es decir:\n",
        "\n",
        "$$I = \\int_{a}^{b} f(x)dx = (b-a) f_{promedio} = (b-a)<f> $$\n",
        "\n",
        "Entonces buscamos una manera de calcular el valor promedio de la función a integrar. Aquí es donde los números aleatorios nos serán útiles. Para encontrar el valor promedio de la función en el intervalo $[a,b]$, primero tomaremos $M$ variables aleatorias $x_i$ uniformemente distribuidas entre $a$ y $b$. Después evaluaremos $f(x_i)$ para todas las muestras tomadas y obtendremos su promedio:\n",
        "\n",
        "$$<f>_M = \\frac{1}{M}\\sum_{i=1}^{M} f(x_i)$$\n",
        "\n",
        "Tenemos que el valor promedio de éstas evaluaciones se aproximara cada vez más a $<f>$ conforme $M \\rightarrow \\infty$. Por lo que obtenemos la siguiente expresión, también conocida como el estimador básico Monte Carlo:\n",
        "\n",
        "$$\\int_{a}^{b} f(x)dx = \\frac{(b-a)}{M}\\sum_{i=1}^{M} f(x_i) $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhNN6yvEjkf9"
      },
      "source": [
        "Vamos a visualizar el teorema del límite central con la integración Monte Carlo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf3XHLKBtBo2"
      },
      "source": [
        "**Bibliotecas Adicionales:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rybido-Vs0En"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from scipy import random\n",
        "from typing import Tuple,Callable\n",
        "from scipy.integrate import quadrature, odeint\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdnPLoXtIK5"
      },
      "source": [
        "Primero vamos a visualizar la distribución de los promedios de una función generados por el método Monte Carlo con ayuda de un histograma. Lo haremos con el ejemplo siguiente:\n",
        "\n",
        "$$\\int_{0}^{\\pi} sin(x)dx = -cos(\\pi) - (-cos(0)) = -(-1)-(-1) = 2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FClTtkBItIcP"
      },
      "source": [
        "def func(x): #Hacemos nuestra función a integrar\n",
        "        return np.sin(x)\n",
        "\n",
        "dom = [0,np.pi]#Intervalo predeterminado\n",
        "\n",
        "def MonteCarlo_int(func,N,dominio = dom):\n",
        "  \"\"\"\n",
        "    :param func: función a integrar\n",
        "    :param N: tamaño de muestra\n",
        "    :param dominio: arreglo con extremos del intervalo a integrar guardados\n",
        "  \"\"\"\n",
        "    \n",
        "  xrand= np.zeros(N) #Inicializamos arreglos que contendrán nuestros puntos aleatorios\n",
        "    \n",
        "  for i in range(N): #Llenamos los arreglos con el debido dominio\n",
        "    xrand[i] = random.uniform(dominio[0],dominio[1])\n",
        "    \n",
        "  integral = 0.0 #Inicializamos variable para resultado\n",
        "    \n",
        "  for i in range (N):\n",
        "    integral += func(xrand[i]) #Evaluamos la función en los puntos aleatorios\n",
        "\n",
        "  ans = integral/N #Dividimos entre el número de iteraciones para encontrar el promedio\n",
        "    \n",
        "  #Finalmente multiplicamos por el área de dominio\n",
        "    \n",
        "  return ans*(dominio[1]-dominio[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "v-yDJpYyEOU9",
        "outputId": "8a1ee63b-17db-4af6-b8f2-f287508b74ec"
      },
      "source": [
        "def Gauss(M):#\n",
        "    Int = [] #Arreglo que guarda los distintos resultados aleatorios de la integración MonteCarlo\n",
        "    for i in range(M):\n",
        "        Int.append(MonteCarlo_int(func,1000))#Definimos el tamaño de los muestreos aleatorios suf grande\n",
        "    return Int\n",
        "\n",
        "M = 1000 #Definimos suf iteraciones para que se note la forma de la distribución más claramente\n",
        "x = range(M)\n",
        "\n",
        "plt.title('Distribución de resultados')   \n",
        "plt.hist(Gauss(M), bins = 30, ec = 'black')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  1.,  3.,  4.,  5., 12.,  9., 13., 27., 33., 46., 48., 59.,\n",
              "        80., 70., 75., 88., 73., 66., 67., 52., 53., 30., 32., 18.,  6.,\n",
              "        10.,  4., 11.,  4.]),\n",
              " array([1.90134662, 1.90741198, 1.91347735, 1.91954271, 1.92560808,\n",
              "        1.93167344, 1.9377388 , 1.94380417, 1.94986953, 1.9559349 ,\n",
              "        1.96200026, 1.96806563, 1.97413099, 1.98019636, 1.98626172,\n",
              "        1.99232708, 1.99839245, 2.00445781, 2.01052318, 2.01658854,\n",
              "        2.02265391, 2.02871927, 2.03478464, 2.04085   , 2.04691536,\n",
              "        2.05298073, 2.05904609, 2.06511146, 2.07117682, 2.07724219,\n",
              "        2.08330755]),\n",
              " <a list of 30 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az6dwaQklmiu"
      },
      "source": [
        "Aquí visualizamos los resultados de la integral, pero como todos los multiplicamos por el mismo intervalo de dominio, también visualizamos la distribución de los promedios generados. Notamos que esta asemeja una campana de Gauss, y refleja el Teorema del Límite Central revisado en el Marco Teórico. Su media con $N$´s suficientemente grandes es el resultado correcto: $2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DUyRNYggnIH"
      },
      "source": [
        "##Error Asociado\n",
        "\n",
        "Nos preguntamos ahora, ¿Qué tan buen estimador de $\\mu_x = \\int_{-\\infty}^{\\infty} xf(x)dx$  es $\\bar{X}$? Revisamos la esperanza de su diferencia.\n",
        "\n",
        "$$\\mathbb{E} (\\bar{X}- \\mu_x)= \\mathbb{E} (\\bar{X}) -\\mu_x = (\\frac{1}{N}\\sum_{i=1}^{N} \\mathbb{E}(x_i)) -\\mu_x $$\n",
        "\n",
        "Como $\\mathbb{E}(x_i) = \\mu_x$ la esperanza de la diferencia es 0.\n",
        "\n",
        "Ahora, su varianza. \n",
        "\n",
        "$$var(\\bar{X}- \\mu_x) = var(\\bar{X})- var(\\mu_x) $$\n",
        "\n",
        "Ya que Monte Carlo toma v.a´s independientes, la varianza de la suma es la suma de sus varianzas. Por lo que\n",
        "\n",
        "$$var(\\bar{X}- \\mu_x) = \\frac{1}{N^2}\\sum_{i=1}^{N} var(x_i) = \\frac{1}{N^2}N\\sigma_x^2 = \\frac{\\sigma_x^2}{N}$$\n",
        "\n",
        "La cantidad $\\sigma_x$  es conocida como la desviación estándar. Por lo que, el error estándar decrece a razón de $\\sqrt{N}$. Es decir, para decrecer la variabilidad en el estimador de la media por un factor de 10 requiere incrementar por un factor de 100 el tamaño de la muestra.\n",
        "\n",
        "Por el Teorema del Límite Central, $\\bar{X}- \\mu_x \\sim \\mathbb{N}(0, \\frac{\\sigma_x^2}{\\sqrt{N}})$\n",
        "\n",
        "Usaremos esto para visualizar el posible error en nuestra solución. Para ello, tomaremos un intervalo de confianza del $99$%. En caso de la distribución normal, ocurre entre 3 desviaciones estándar. Es decir,\n",
        "\n",
        "$$\\mathbb{P}[-3 \\frac{\\sigma_x}{\\sqrt{N}} <\\bar{X}-\\mu_x <3\\frac{\\sigma_x}{\\sqrt{N}}] \\sim 0.99$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS0Br4IPW1Dh"
      },
      "source": [
        "#Desarrollo\n",
        "\n",
        "Ahora estamos listos para la implementación combinada de EDO´s e integración Monte Carlo. Consideraremos la forma de EDO:\n",
        "\n",
        "$$\\frac{dx}{dt} = f(t,x(t))$$\n",
        "\n",
        "con $x(t_0)=x_0$ valor inicial de la ecuación. También utilizaremos el resultado que indica que podemos considerarla de la siguiente forma:\n",
        "\n",
        "$$x(t) = x_0 + \\int_{t_0}^{t} f(s,x(s))ds$$\n",
        "\n",
        "que discretizamos a pedazos más pequeños, pasando a:\n",
        "\n",
        "$$x(t) = x_0 + \\sum_{i=1}^{N} \\int_{t_{i-1}}^{t_i} f(s,x(s))ds$$\n",
        "\n",
        "Aplicando el Estimador Monte Carlo:\n",
        "\n",
        "$$x(t) = x_0 + \\sum_{i=1}^{N} [ \\frac{t_i - t_{i-1}}{k} \\sum_{k=1}^{K} f(t_k)]$$\n",
        "\n",
        "Que puede reescribirse como el proceso iterativo:\n",
        "\n",
        "$$x(t_i) = x(t_{i-1}) +  \\frac{t_i - t_{i-1}}{k} \\sum_{k=1}^{K} f(t_k)$$\n",
        "\n",
        "Que también podemos ver como:\n",
        "\n",
        "$$x(t_i) = x(t_{i-1}) +  \\mathbb{E}_{t \\sim \\mathbb{U}(t_{i-1},t_i)}[f(t)]$$\n",
        "\n",
        "Podemos ver que podemos resolver la EDO con una muestra de variables aleatorias distribuidas uniformemente y evaluando la función $f$ en ellas. No necesitamos una malla que se adapte u otro método para estimar el tamaño de los pasos, solo un buen muestreo aleatorio. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMMeSrVUk6Xc"
      },
      "source": [
        "##Implementación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXBkR_GGKQqF"
      },
      "source": [
        "Ahora la resolución de una EDO de primer orden lineal. Recordemos que una EDO de primer orden es aquella donde sólo está presente la primera derivada de $x$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSgrBrLiNe7P"
      },
      "source": [
        "def mi_ode(func, x0, t, N=1):\n",
        "    \"\"\"\n",
        "    :param func: función del campo gradiente\n",
        "    :param x0: Valor inicial\n",
        "    :param t: Dominio de puntos sobre las cuales el campo de func debería ser integrado\n",
        "    :param N: tamaño de muestra aleatoria\n",
        "    \"\"\"\n",
        "    vals = [x0]\n",
        "    for lo, hi in zip(t[:-1], t[1:]):\n",
        "        vals.append(vals[-1] + MonteCarlo_int(func, N, [lo, hi]))\n",
        "    return vals\n",
        "\n",
        "#EDO Lineal\n",
        "\n",
        "def funclin(t):\n",
        "    return t**3 + 2 * t**2 - 3**t\n",
        "\n",
        "\n",
        "def analitica(t):\n",
        "  k = -2-(((-2)**4)/4 + (2/3)*((-2)**3) - (3**(-2)/np.log(3)))\n",
        "  return (t**4)/4 + (2/3)*(t**3) - (3**t/np.log(3)) +k\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqW1ABk7Os5m"
      },
      "source": [
        "ts = np.linspace(-2.0, 2.0, 10) #establecemos un espacio de tiempo donde queremos ver la solución\n",
        "x0 = -2.0 #Establecemos condición inicial\n",
        "xs = [] #Arreglo de arreglos resultado de mi_ode\n",
        "for i in range(10):\n",
        "    ans = mi_ode(funclin, x0, ts)\n",
        "    xs.append(ans)\n",
        "\n",
        "x_mean = np.mean(xs, axis=0) #Promedio de la columna\n",
        "\n",
        "#Vamos a cambiar los parámetros de la imagen ya que por default se ve muy pequeña\n",
        "width = 15\n",
        "height = width / 1.65\n",
        "fig = plt.figure(figsize=(width, height))\n",
        "\n",
        "ys = analitica(ts)\n",
        "\n",
        "plt.plot(ts, x_mean, linewidth=6, label='Solución Monte Carlo N=10')\n",
        "plt.plot(ts, ys, linewidth=3, label='Solución analítica', color= 'red')\n",
        "\n",
        "errorg = []\n",
        "for i in ts:\n",
        "  errorg.append(abs(ys-x_mean))\n",
        "\n",
        "\n",
        "#Vamos a graficar el campo vectorial\n",
        "tt, xx = np.meshgrid(np.linspace(min(ts), max(ts), 10), np.linspace(-3, 3, 10))\n",
        "U = 1\n",
        "V = funclin(tt)\n",
        "N = np.sqrt(U**2 + V ** 2)\n",
        "U2, V2 = U/N, V/N\n",
        "plt.quiver(tt, xx, U2, V2, color='lightgray', label='Campo vectorial')\n",
        "\n",
        "#Graficamos la solución con el campo vectorial\n",
        "plt.xlabel(r't', fontsize=20)\n",
        "plt.ylabel(r'x', fontsize=20)\n",
        "plt.tick_params(axis='both', which='major', labelsize=16)\n",
        "plt.tick_params(axis='both', which='minor', labelsize=12)\n",
        "plt.legend(loc='upper left', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q0cAftoxJKz"
      },
      "source": [
        "ts = np.linspace(-2.0, 2.0, 10) #establecemos un espacio de tiempo donde queremos ver la solución\n",
        "x0 = -2.0 #Establecemos condición inicial\n",
        "xs = [] #Arreglo de arreglos resultado de mi_ode\n",
        "for i in range(100):\n",
        "    ans = mi_ode(funclin, x0, ts)\n",
        "    xs.append(ans)\n",
        "\n",
        "x_mean = np.mean(xs, axis=0) #Promedio de la columna\n",
        "\n",
        "#Vamos a cambiar los parámetros de la imagen ya que por default se ve muy pequeña\n",
        "width = 15\n",
        "height = width / 1.65\n",
        "fig = plt.figure(figsize=(width, height))\n",
        "\n",
        "plt.plot(ts, x_mean, linewidth=6, label='Solución Monte Carlo N =100')\n",
        "plt.plot(ts, ys, linewidth=3, label='Solución analítica', color= 'red')\n",
        "\n",
        "errorc = []\n",
        "for i in ts:\n",
        "  errorc.append(abs(ys-x_mean))\n",
        "\n",
        "\n",
        "\n",
        "#Vamos a graficar el campo vectorial\n",
        "tt, xx = np.meshgrid(np.linspace(min(ts), max(ts), 10), np.linspace(-3, 3, 10))\n",
        "U = 1\n",
        "V = funclin(tt)\n",
        "N = np.sqrt(U**2 + V ** 2)\n",
        "U2, V2 = U/N, V/N\n",
        "plt.quiver(tt, xx, U2, V2, color='lightgray', label='Campo vectorial')\n",
        "\n",
        "#Graficamos la solución con el campo vectorial\n",
        "plt.xlabel(r't', fontsize=20)\n",
        "plt.ylabel(r'x', fontsize=20)\n",
        "plt.tick_params(axis='both', which='major', labelsize=16)\n",
        "plt.tick_params(axis='both', which='minor', labelsize=12)\n",
        "plt.legend(loc='upper left', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "nh2C5m9iysrN",
        "outputId": "b6726059-6170-4ecc-cc01-524211bc37b1"
      },
      "source": [
        "x_std = np.std(xs, axis=0) #Desviación estándar de la columna\n",
        "\n",
        "#Vamos a cambiar los parámetros de la imagen ya que por default se ve muy pequeña\n",
        "width = 15\n",
        "height = width / 1.65\n",
        "fig = plt.figure(figsize=(width, height))\n",
        "\n",
        "plt.plot(ts, x_mean, linewidth=3, label='Solución Monte Carlo')\n",
        "plt.fill_between(ts, x_mean - 3 * x_std, x_mean + 3 * x_std, alpha=.75, color='r', label='Error asociado MC')\n",
        "\n",
        "#Vamos a graficar el campo vectorial\n",
        "tt, xx = np.meshgrid(np.linspace(min(ts), max(ts), 10), np.linspace(-3, 3, 10))\n",
        "U = 1\n",
        "V = funclin(tt)\n",
        "N = np.sqrt(U**2 + V ** 2)\n",
        "U2, V2 = U/N, V/N\n",
        "plt.quiver(tt, xx, U2, V2, color='lightgray', label='Campo vectorial')\n",
        "\n",
        "#Graficamos la solución con el campo vectorial y una solución por otro método\n",
        "plt.xlabel(r't', fontsize=20)\n",
        "plt.ylabel(r'x', fontsize=20)\n",
        "plt.tick_params(axis='both', which='major', labelsize=16)\n",
        "plt.tick_params(axis='both', which='minor', labelsize=12)\n",
        "plt.legend(loc='upper left', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f3fb24dbca36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Desviación estándar de la columna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Vamos a cambiar los parámetros de la imagen ya que por default se ve muy pequeña\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.65\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRkeIHswW36U"
      },
      "source": [
        "#Análisis de resultados\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtqmFULz32nz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgn1HYd73fsD"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Tamaño de Muestra', 'Error máximo', 'Promedio de error'])\n",
        "t.add_row(['N=10', np.amax(errorc),np.mean(errorc)])\n",
        "t.add_row(['N=100', np.amax(errorg),np.mean(errorg)])\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfG66CS333bQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fitUYGZW-U-"
      },
      "source": [
        "#Conclusiones\n",
        "\n",
        "1. Para este tipo de problemas la implementación de Monte Carlo resulta muy sencilla gracias a su flexibilidad. \n",
        "\n",
        "2. En el caso de la solución de ecuaciones diferenciales no debemos olvidar que el tamaño del intervalo de tiempo y qué tan \"fina\" hagamos la partición del intervalo  afecta como se comporta la desviación estándar. El resultado es más cercano conforme más fina sea.\n",
        "\n",
        "3. El método Monte Carlo es computacionalmente más costoso que otros solvers de EDO´s y como todo el proyecto indica que lo fundamental es un muestreo de buen tamaño, preguntarse si vale o no su implementación depende de que tan posible sea otorgárselo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGwjjMD5XA4X"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "*  Akhtar, Muhammad Naveed  [et al](http://static.bsu.az/w24/PIAMV4%20N2%202015/6%20Akhtar.pdf). SOLVING INITIAL VALUE ORDINARY DIFFERENTIAL EQUATIONS\n",
        "BY MONTE CARLO METHOD, Proceedings of IAM, V.4, N.2, 2015, pp.149-174.\n",
        "* [Teoremas importantes](https://www.ugr.es/~jillana/Docencia/FM/mc.pdf).\n",
        "* [Monte Carlo Integration](hhttps://inst.eecs.berkeley.edu/~cs294-13/fa09/lectures/scribe-lecture4.pdf).\n",
        "* [Monte Carlo Estimator](https://cs.dartmouth.edu/wjarosz/publications/dissertation/appendixA.pdf).\n",
        "*[Error Estimates for MC](https://ocw.mit.edu/courses/aeronautics-and-astronautics/16-90-computational-methods-in-aerospace-engineering-spring-2014/probabilistic-methods-and-optimization/error-estimates-for-the-monte-carlo-method/)\n",
        "*Otterbach, Johannes. Blog entry : How to Solve ODES with Monte Carlo Method\n",
        "*N, Metroplis. THE BEGINNING of the\n",
        "MONTE CARLO METHOD. Los Alamos Science Special issue, 1987, pp.125-130"
      ]
    }
  ]
}